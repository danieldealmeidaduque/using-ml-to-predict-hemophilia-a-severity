\begin{tabular}{lllllll}
\toprule
Classifier & Scaler & Accuracy & ROC AUC OVR & F1 & Recall & Best Hyperparameters Values \\
\midrule
RandomForest & Standard & 0.655 (0.06, 0.63, 0.68) & 0.744 (0.08, 0.72, 0.77) & 0.548 (0.08, 0.52, 0.57) & 0.555 (0.07, 0.53, 0.58) & {{n\_estimators: 200}} \\
RandomForest & None & 0.651 (0.07, 0.63, 0.67) & 0.748 (0.08, 0.72, 0.78) & 0.544 (0.08, 0.52, 0.57) & 0.552 (0.07, 0.53, 0.57) & {{n\_estimators: 200}} \\
XGBoost & None & 0.639 (0.08, 0.61, 0.67) & 0.723 (0.08, 0.69, 0.75) & 0.554 (0.08, 0.53, 0.58) & 0.556 (0.08, 0.53, 0.58) & {{learning\_rate: 1.0, n\_estimators: 200}} \\
XGBoost & Standard & 0.637 (0.08, 0.61, 0.67) & 0.722 (0.08, 0.69, 0.75) & 0.555 (0.08, 0.53, 0.58) & 0.555 (0.08, 0.53, 0.58) & {{n\_estimators: 50, learning\_rate: 0.1}} \\
Bagging & None & 0.635 (0.08, 0.61, 0.66) & 0.735 (0.08, 0.71, 0.76) & 0.530 (0.09, 0.50, 0.56) & 0.539 (0.08, 0.51, 0.57) & {{n\_estimators: 200}} \\
GradientBoosting & Standard & 0.634 (0.07, 0.61, 0.66) & 0.710 (0.08, 0.68, 0.74) & 0.521 (0.07, 0.49, 0.55) & 0.531 (0.07, 0.51, 0.56) & {{n\_estimators: 50, learning\_rate: 0.1}} \\
Bagging & Standard & 0.633 (0.07, 0.61, 0.66) & 0.734 (0.07, 0.71, 0.76) & 0.527 (0.08, 0.50, 0.56) & 0.536 (0.07, 0.51, 0.56) & {{n\_estimators: 200}} \\
GradientBoosting & None & 0.630 (0.08, 0.60, 0.66) & 0.711 (0.08, 0.68, 0.74) & 0.523 (0.08, 0.49, 0.55) & 0.531 (0.08, 0.50, 0.56) & {{n\_estimators: 50, learning\_rate: 0.1}} \\
LightGBM & Standard & 0.623 (0.07, 0.60, 0.65) & 0.712 (0.09, 0.68, 0.74) & 0.507 (0.09, 0.48, 0.54) & 0.521 (0.07, 0.49, 0.55) & {{n\_estimators: 100, learning\_rate: 0.01}} \\
LightGBM & None & 0.622 (0.07, 0.59, 0.65) & 0.705 (0.08, 0.68, 0.73) & 0.511 (0.08, 0.48, 0.54) & 0.522 (0.07, 0.50, 0.55) & {{learning\_rate: 0.01, n\_estimators: 200}} \\
AdaBoost & None & 0.581 (0.07, 0.56, 0.60) & 0.659 (0.08, 0.63, 0.69) & 0.439 (0.07, 0.41, 0.47) & 0.468 (0.06, 0.45, 0.49) & {{learning\_rate: 1.0, n\_estimators: 100}} \\
AdaBoost & Standard & 0.581 (0.07, 0.56, 0.60) & 0.659 (0.08, 0.63, 0.69) & 0.439 (0.07, 0.41, 0.47) & 0.468 (0.06, 0.45, 0.49) & {{learning\_rate: 1.0, n\_estimators: 100}} \\
KNeighbors & None & 0.578 (0.08, 0.55, 0.60) & 0.672 (0.08, 0.64, 0.70) & 0.491 (0.08, 0.46, 0.52) & 0.497 (0.08, 0.47, 0.52) & {{n\_neighbors: 3}} \\
DecisionTree & Standard & 0.577 (0.07, 0.55, 0.60) & 0.652 (0.07, 0.62, 0.68) & 0.468 (0.07, 0.44, 0.49) & 0.478 (0.07, 0.45, 0.50) & {{max\_depth: 3}} \\
DecisionTree & None & 0.574 (0.08, 0.55, 0.60) & 0.651 (0.08, 0.62, 0.68) & 0.464 (0.09, 0.43, 0.49) & 0.477 (0.08, 0.45, 0.51) & {{max\_depth: 3}} \\
KNeighbors & Standard & 0.549 (0.07, 0.53, 0.57) & 0.643 (0.07, 0.62, 0.67) & 0.442 (0.07, 0.42, 0.47) & 0.454 (0.06, 0.43, 0.48) & {{n\_neighbors: 7}} \\
GaussianNB & None & 0.511 (0.06, 0.49, 0.53) & 0.672 (0.08, 0.65, 0.70) & 0.355 (0.06, 0.33, 0.38) & 0.398 (0.05, 0.38, 0.41) & {{}} \\
GaussianNB & Standard & 0.478 (0.06, 0.46, 0.50) & 0.664 (0.08, 0.64, 0.69) & 0.295 (0.07, 0.27, 0.32) & 0.368 (0.05, 0.35, 0.39) & {{}} \\
Dummy & None & 0.463 (0.01, 0.46, 0.47) & 0.500 (0.00, nan, nan) & 0.211 (0.00, 0.21, 0.21) & 0.333 (0.00, 0.33, 0.33) & {{strategy: most\_frequent}} \\
Dummy & Standard & 0.463 (0.01, 0.46, 0.47) & 0.500 (0.00, nan, nan) & 0.211 (0.00, 0.21, 0.21) & 0.333 (0.00, 0.33, 0.33) & {{strategy: most\_frequent}} \\
\bottomrule
\end{tabular}
